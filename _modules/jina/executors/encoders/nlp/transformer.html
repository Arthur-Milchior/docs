

<!DOCTYPE html>
<html lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="X-UA-Compatible" content="IE=edge">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@JinaAI_">
<meta name="twitter:creator" content="@JinaAI_">
<meta name="description"
      content="Jina is the cloud-native neural search solution powered by the state-of-the-art AI and deep learning">
<meta property="og:title" content="Jina Documentation">
<meta property="og:description"
      content="Jina is the cloud-native neural search solution powered by the state-of-the-art AI and deep learning">
<meta property="og:url" content="https://opensource.jina.ai">
<meta property="og:image" content="../../../../../_static/banner.png">
<meta property="og:type" content="website">
<link rel="icon" href="../../../../../_static/favicon.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
  <title>jina.executors.encoders.nlp.transformer &mdash; Jina 0.2.0 documentation</title>
  

  
  <link rel="stylesheet" href="../../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../_static/main.css" type="text/css" />

<!--  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/1.0.0/css/materialize.min.css">-->


  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../../" src="../../../../../_static/documentation_options.js"></script>
        <script src="../../../../../_static/jquery.js"></script>
        <script src="../../../../../_static/underscore.js"></script>
        <script src="../../../../../_static/doctools.js"></script>
        <script src="../../../../../_static/language_data.js"></script>
        <script src="../../../../../_static/clipboard.min.js"></script>
        <script src="../../../../../_static/copybutton.js"></script>
    
    <script type="text/javascript" src="../../../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../../index.html">
          

          
            
            <img src="../../../../../_static/jina-prod-logo.svg" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.2.0
              </div>
            
          


          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Install</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/install/via-pip.html">Install Jina via <code class="docutils literal notranslate"><span class="pre">pip</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/install/via-docker.html">Install Jina via Docker Container</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/install/on-rasp-linux.html">Install Jina on Raspberry Pi and other Linux Systems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/install/upgrade.html">Upgrade Jina</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/install/autocomplete.html">Autocomplete commands on Bash, Zsh and Fish</a></li>
</ul>
<p class="caption"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/helloworld/main.html">Jina ‚ÄúHello, World!‚Äù üëãüåç</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/101/.sphinx.html">Jina 101: First Thing to Learn About Jina</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/flow/README.html">Using Flow API to Compose Your Jina Workflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/io/main.html">Input and Output Functions in Jina</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/hub/main.html">Using Jina Pod with Docker Container</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/remote/main.html">Using Jina Pod Remotely</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/dashboard/main.html">Using Dashboard to Monitor Logs and View Flow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/cli/exit.html">Gracefully Exit Jina</a></li>
</ul>
<p class="caption"><span class="caption-text">Developer Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/cli/main.html">Jina Command-Line Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../api/jina.html">Jina Python API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/yaml/yaml.html">Jina YAML Syntax Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/simple_exec.html">Built-in Simple Executors and Reserved <code class="docutils literal notranslate"><span class="pre">yaml-path</span></code> in Jina</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/proto/main.html">Jina Protobuf Specification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/restapi/main.html">Jina REST API Specification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/envs.html">OS Environment Variables Used in Jina</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/api_schema.html">Jina API Schema for 3rd-Party Applications</a></li>
</ul>
<p class="caption"><span class="caption-text">Extending Jina</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/extend/mwu.html">A Minimum Working Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/extend/executor.html">Guideline When Adding New Executor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/extend/driver.html">Guideline When Adding New Driver</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/hub/publish-your-pod-image.html">Publish Your Pod Image to Jina Hub</a></li>
</ul>
<p class="caption"><span class="caption-text">Contributing</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/CONTRIBUTING.html">Contributing Guideline</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/jep/main.html">Jina Enhancement Proposals (JEP)</a></li>
</ul>
<p class="caption"><span class="caption-text">Release Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/RELEASE.html">Release Cycle</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/CHANGELOG.html">Change Logs</a></li>
</ul>
<p class="caption"><span class="caption-text">Debugging and FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/troubleshooting.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/faq/user.html">FAQ for End-Users</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/faq/dev.html">FAQ for Developers</a></li>
</ul>
<p class="caption"><span class="caption-text">Indices and Tables</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/all_exec.html">List of 80 Executors in Jina</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/all_driver.html">List of 35 Drivers in Jina</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../index.html">Jina</a>
        
      </nav>

      <div class="card table-of-contents">
          <span class="card-title">Table of Contents</span>
            <div class="card-content">
            
            </div>
        <a href="https://github.com/jina-ai/jina/">
          <span class="toc-card-footer">
            <span>Visit us on Github</span>
          </span>
        </a>
      </div>

      <div id="showhide-navbar-btn" onclick="showhide_navbar()">
      </div>

      <div class="wy-nav-content">
        
        <div class="rst-content style-external-links">
        
          















<div role="navigation" aria-label="breadcrumbs navigation" class="nav-bar-header">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../../../../index.html">Module code</a> &raquo;</li>
        
          <li><a href="../../../../jina.html">jina</a> &raquo;</li>
        
          <li><a href="../../../executors.html">jina.executors</a> &raquo;</li>
        
          <li><a href="../../encoders.html">jina.executors.encoders</a> &raquo;</li>
        
      <li>jina.executors.encoders.nlp.transformer</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  
<div role="search" class="nav-bar-search">
  <form id="rtd-search-form" class="wy-form doc-searchbox" action="../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

</div>
<hr/>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for jina.executors.encoders.nlp.transformer</h1><div class="highlight"><pre>
<span></span><span class="n">__copyright__</span> <span class="o">=</span> <span class="s2">&quot;Copyright (c) 2020 Jina AI Limited. All rights reserved.&quot;</span>
<span class="n">__license__</span> <span class="o">=</span> <span class="s2">&quot;Apache-2.0&quot;</span>

<span class="kn">import</span> <span class="nn">os</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">..</span> <span class="kn">import</span> <span class="n">BaseEncoder</span>
<span class="kn">from</span> <span class="nn">..frameworks</span> <span class="kn">import</span> <span class="n">BaseTextTFEncoder</span><span class="p">,</span> <span class="n">BaseTextTorchEncoder</span>
<span class="kn">from</span> <span class="nn">..helper</span> <span class="kn">import</span> <span class="n">reduce_mean</span><span class="p">,</span> <span class="n">reduce_max</span><span class="p">,</span> <span class="n">reduce_min</span><span class="p">,</span> <span class="n">reduce_cls</span>
<span class="kn">from</span> <span class="nn">...decorators</span> <span class="kn">import</span> <span class="n">batching</span><span class="p">,</span> <span class="n">as_ndarray</span>


<div class="viewcode-block" id="BaseTransformerEncoder"><a class="viewcode-back" href="../../../../../api/jina.executors.encoders.nlp.transformer.html#jina.executors.encoders.nlp.transformer.BaseTransformerEncoder">[docs]</a><span class="k">class</span> <span class="nc">BaseTransformerEncoder</span><span class="p">(</span><span class="n">BaseEncoder</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    :class:`TransformerTextEncoder` encodes data from an array of string in size `B` into an ndarray in size `B x D`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">pooling_strategy</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;mean&#39;</span><span class="p">,</span>
                 <span class="n">max_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span>
                 <span class="n">model_path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;transformer&#39;</span><span class="p">,</span>
                 <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        :param model_name: the name of the model. Supported models include &#39;bert-base-uncased&#39;, &#39;openai-gpt&#39;, &#39;gpt2&#39;,</span>
<span class="sd">            &#39;xlm-mlm-enfr-1024&#39;, &#39;distilbert-base-cased&#39;, &#39;roberta-base&#39;, &#39;xlm-roberta-base&#39;, &#39;flaubert-base-cased&#39;,</span>
<span class="sd">            &#39;camembert-base&#39;, &#39;ctrl&#39;.</span>
<span class="sd">        :param pooling_strategy: the strategy to merge the word embeddings into the chunk embedding. Supported</span>
<span class="sd">            strategies include &#39;cls&#39;, &#39;mean&#39;, &#39;max&#39;, &#39;min&#39;.</span>
<span class="sd">        :param max_length: the max length to truncate the tokenized sequences to.</span>
<span class="sd">        :param model_path: the path of the encoder model. If a valid path is given, the encoder will be loaded from the</span>
<span class="sd">            given path.</span>

<span class="sd">        ..warning::</span>
<span class="sd">            `model_path` is a relative path in the executor&#39;s workspace.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="o">=</span> <span class="s1">&#39;bert-base-uncased&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pooling_strategy</span> <span class="o">=</span> <span class="n">pooling_strategy</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_length</span> <span class="o">=</span> <span class="n">max_length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">raw_model_path</span> <span class="o">=</span> <span class="n">model_path</span>

<div class="viewcode-block" id="BaseTransformerEncoder.encode"><a class="viewcode-back" href="../../../../../api/jina.executors.encoders.nlp.transformer.html#jina.executors.encoders.nlp.transformer.BaseTransformerEncoder.encode">[docs]</a>    <span class="nd">@batching</span>
    <span class="nd">@as_ndarray</span>
    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="s1">&#39;np.ndarray&#39;</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s1">&#39;np.ndarray&#39;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        :param data: a 1d array of string type in size `B`</span>
<span class="sd">        :return: an ndarray in size `B x D`</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">token_ids_batch</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">mask_ids_batch</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">c_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">token_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span>
                <span class="n">data</span><span class="p">[</span><span class="n">c_idx</span><span class="p">],</span> <span class="n">pad_to_max_length</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_length</span><span class="p">)</span>
            <span class="n">mask_ids</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">if</span> <span class="n">t</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="k">else</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">token_ids</span><span class="p">]</span>
            <span class="n">token_ids_batch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token_ids</span><span class="p">)</span>
            <span class="n">mask_ids_batch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mask_ids</span><span class="p">)</span>
        <span class="n">token_ids_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">array2tensor</span><span class="p">(</span><span class="n">token_ids_batch</span><span class="p">)</span>
        <span class="n">mask_ids_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">array2tensor</span><span class="p">(</span><span class="n">mask_ids_batch</span><span class="p">)</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">():</span>
            <span class="n">seq_output</span><span class="p">,</span> <span class="o">*</span><span class="n">extra_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">token_ids_batch</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">mask_ids_batch</span><span class="p">)</span>
            <span class="n">_mask_ids_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor2array</span><span class="p">(</span><span class="n">mask_ids_batch</span><span class="p">)</span>
            <span class="n">_seq_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor2array</span><span class="p">(</span><span class="n">seq_output</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pooling_strategy</span> <span class="o">==</span> <span class="s1">&#39;cls&#39;</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span><span class="p">,</span> <span class="s1">&#39;cls_token&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">extra_output</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor2array</span><span class="p">(</span><span class="n">extra_output</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">output</span> <span class="o">=</span> <span class="n">reduce_cls</span><span class="p">(</span><span class="n">_seq_output</span><span class="p">,</span> <span class="n">_mask_ids_batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cls_pos</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">pooling_strategy</span> <span class="o">==</span> <span class="s1">&#39;mean&#39;</span><span class="p">:</span>
                <span class="n">output</span> <span class="o">=</span> <span class="n">reduce_mean</span><span class="p">(</span><span class="n">_seq_output</span><span class="p">,</span> <span class="n">_mask_ids_batch</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">pooling_strategy</span> <span class="o">==</span> <span class="s1">&#39;max&#39;</span><span class="p">:</span>
                <span class="n">output</span> <span class="o">=</span> <span class="n">reduce_max</span><span class="p">(</span><span class="n">_seq_output</span><span class="p">,</span> <span class="n">_mask_ids_batch</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">pooling_strategy</span> <span class="o">==</span> <span class="s1">&#39;min&#39;</span><span class="p">:</span>
                <span class="n">output</span> <span class="o">=</span> <span class="n">reduce_min</span><span class="p">(</span><span class="n">_seq_output</span><span class="p">,</span> <span class="n">_mask_ids_batch</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">&quot;pooling strategy not found: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pooling_strategy</span><span class="p">))</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span>
        <span class="k">return</span> <span class="n">output</span></div>

    <span class="k">def</span> <span class="nf">__getstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_abspath</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;create folder for saving transformer models: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_abspath</span><span class="p">))</span>
            <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_abspath</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_abspath</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_abspath</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__getstate__</span><span class="p">()</span>

<div class="viewcode-block" id="BaseTransformerEncoder.post_init"><a class="viewcode-back" href="../../../../../api/jina.executors.encoders.nlp.transformer.html#jina.executors.encoders.nlp.transformer.BaseTransformerEncoder.post_init">[docs]</a>    <span class="k">def</span> <span class="nf">post_init</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_tensor_func</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_sess_func</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tmp_model_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_abspath</span> <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_abspath</span><span class="p">)</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_tokenizer</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cls_pos</span> <span class="o">=</span> <span class="s1">&#39;tail&#39;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="o">==</span> <span class="s1">&#39;xlnet-base-cased&#39;</span> <span class="k">else</span> <span class="s1">&#39;head&#39;</span></div>

<div class="viewcode-block" id="BaseTransformerEncoder.array2tensor"><a class="viewcode-back" href="../../../../../api/jina.executors.encoders.nlp.transformer.html#jina.executors.encoders.nlp.transformer.BaseTransformerEncoder.array2tensor">[docs]</a>    <span class="k">def</span> <span class="nf">array2tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">array</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_func</span><span class="p">(</span><span class="n">array</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseTransformerEncoder.tensor2array"><a class="viewcode-back" href="../../../../../api/jina.executors.encoders.nlp.transformer.html#jina.executors.encoders.nlp.transformer.BaseTransformerEncoder.tensor2array">[docs]</a>    <span class="k">def</span> <span class="nf">tensor2array</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">tensor</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">model_abspath</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Get the file path of the encoder model storage</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_file_from_workspace</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_model_path</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_model</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">session</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_func</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_sess_func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_func</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">tensor_func</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor_func</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_tensor_func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_tensor_func</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor_func</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">tokenizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_tokenizer</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span>

<div class="viewcode-block" id="BaseTransformerEncoder.get_tokenizer"><a class="viewcode-back" href="../../../../../api/jina.executors.encoders.nlp.transformer.html#jina.executors.encoders.nlp.transformer.BaseTransformerEncoder.get_tokenizer">[docs]</a>    <span class="k">def</span> <span class="nf">get_tokenizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">BertTokenizer</span><span class="p">,</span> <span class="n">OpenAIGPTTokenizer</span><span class="p">,</span> <span class="n">GPT2Tokenizer</span><span class="p">,</span> \
            <span class="n">XLNetTokenizer</span><span class="p">,</span> <span class="n">XLMTokenizer</span><span class="p">,</span> <span class="n">DistilBertTokenizer</span><span class="p">,</span> <span class="n">RobertaTokenizer</span><span class="p">,</span> <span class="n">XLMRobertaTokenizer</span><span class="p">,</span> \
            <span class="n">FlaubertTokenizer</span><span class="p">,</span> <span class="n">CamembertTokenizer</span><span class="p">,</span> <span class="n">CTRLTokenizer</span>
        <span class="n">tokenizer_dict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;bert-base-uncased&#39;</span><span class="p">:</span> <span class="n">BertTokenizer</span><span class="p">,</span>
            <span class="s1">&#39;openai-gpt&#39;</span><span class="p">:</span> <span class="n">OpenAIGPTTokenizer</span><span class="p">,</span>
            <span class="s1">&#39;gpt2&#39;</span><span class="p">:</span> <span class="n">GPT2Tokenizer</span><span class="p">,</span>
            <span class="s1">&#39;xlnet-base-cased&#39;</span><span class="p">:</span> <span class="n">XLNetTokenizer</span><span class="p">,</span>
            <span class="s1">&#39;xlm-mlm-enfr-1024&#39;</span><span class="p">:</span> <span class="n">XLMTokenizer</span><span class="p">,</span>
            <span class="s1">&#39;distilbert-base-cased&#39;</span><span class="p">:</span> <span class="n">DistilBertTokenizer</span><span class="p">,</span>
            <span class="s1">&#39;roberta-base&#39;</span><span class="p">:</span> <span class="n">RobertaTokenizer</span><span class="p">,</span>
            <span class="s1">&#39;xlm-roberta-base&#39;</span><span class="p">:</span> <span class="n">XLMRobertaTokenizer</span><span class="p">,</span>
            <span class="s1">&#39;flaubert-base-cased&#39;</span><span class="p">:</span> <span class="n">FlaubertTokenizer</span><span class="p">,</span>
            <span class="s1">&#39;camembert-base&#39;</span><span class="p">:</span> <span class="n">CamembertTokenizer</span><span class="p">,</span>
            <span class="s1">&#39;ctrl&#39;</span><span class="p">:</span> <span class="n">CTRLTokenizer</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">tokenizer_dict</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1"> not in our supports: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="p">,</span> <span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tokenizer_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())))</span>
            <span class="k">raise</span> <span class="ne">ValueError</span>
        <span class="n">_tokenizer</span> <span class="o">=</span> <span class="n">tokenizer_dict</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="p">]</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tmp_model_path</span><span class="p">)</span>
        <span class="n">_tokenizer</span><span class="o">.</span><span class="n">padding_side</span> <span class="o">=</span> <span class="s1">&#39;right&#39;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;openai-gpt&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt2&#39;</span><span class="p">,</span> <span class="s1">&#39;xlm-mlm-enfr-1024&#39;</span><span class="p">,</span> <span class="s1">&#39;xlnet-base-cased&#39;</span><span class="p">):</span>
            <span class="n">_tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="s1">&#39;&lt;PAD&gt;&#39;</span>
        <span class="k">return</span> <span class="n">_tokenizer</span></div>

<div class="viewcode-block" id="BaseTransformerEncoder.get_cls_pos"><a class="viewcode-back" href="../../../../../api/jina.executors.encoders.nlp.transformer.html#jina.executors.encoders.nlp.transformer.BaseTransformerEncoder.get_cls_pos">[docs]</a>    <span class="k">def</span> <span class="nf">get_cls_pos</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s1">&#39;tail&#39;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="o">==</span> <span class="s1">&#39;xlnet-base-cased&#39;</span> <span class="k">else</span> <span class="s1">&#39;head&#39;</span></div>

<div class="viewcode-block" id="BaseTransformerEncoder.get_tmp_model_path"><a class="viewcode-back" href="../../../../../api/jina.executors.encoders.nlp.transformer.html#jina.executors.encoders.nlp.transformer.BaseTransformerEncoder.get_tmp_model_path">[docs]</a>    <span class="k">def</span> <span class="nf">get_tmp_model_path</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_abspath</span> <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_abspath</span><span class="p">)</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span></div>

<div class="viewcode-block" id="BaseTransformerEncoder.get_model"><a class="viewcode-back" href="../../../../../api/jina.executors.encoders.nlp.transformer.html#jina.executors.encoders.nlp.transformer.BaseTransformerEncoder.get_model">[docs]</a>    <span class="k">def</span> <span class="nf">get_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>

<div class="viewcode-block" id="BaseTransformerEncoder.get_session"><a class="viewcode-back" href="../../../../../api/jina.executors.encoders.nlp.transformer.html#jina.executors.encoders.nlp.transformer.BaseTransformerEncoder.get_session">[docs]</a>    <span class="k">def</span> <span class="nf">get_session</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>

<div class="viewcode-block" id="BaseTransformerEncoder.get_tensor_func"><a class="viewcode-back" href="../../../../../api/jina.executors.encoders.nlp.transformer.html#jina.executors.encoders.nlp.transformer.BaseTransformerEncoder.get_tensor_func">[docs]</a>    <span class="k">def</span> <span class="nf">get_tensor_func</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div></div>


<div class="viewcode-block" id="TransformerTFEncoder"><a class="viewcode-back" href="../../../../../api/jina.executors.encoders.nlp.transformer.html#jina.executors.encoders.nlp.transformer.TransformerTFEncoder">[docs]</a><span class="k">class</span> <span class="nc">TransformerTFEncoder</span><span class="p">(</span><span class="n">BaseTransformerEncoder</span><span class="p">,</span> <span class="n">BaseTextTFEncoder</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Internally, TransformerTFEncoder wraps the tensorflow-version of transformers from huggingface.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="TransformerTFEncoder.get_model"><a class="viewcode-back" href="../../../../../api/jina.executors.encoders.nlp.transformer.html#jina.executors.encoders.nlp.transformer.TransformerTFEncoder.get_model">[docs]</a>    <span class="k">def</span> <span class="nf">get_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TFBertModel</span><span class="p">,</span> <span class="n">TFOpenAIGPTModel</span><span class="p">,</span> <span class="n">TFGPT2Model</span><span class="p">,</span> <span class="n">TFXLNetModel</span><span class="p">,</span> <span class="n">TFXLMModel</span><span class="p">,</span> \
            <span class="n">TFDistilBertModel</span><span class="p">,</span> <span class="n">TFRobertaModel</span><span class="p">,</span> <span class="n">TFXLMRobertaModel</span><span class="p">,</span> <span class="n">TFCamembertModel</span><span class="p">,</span> <span class="n">TFCTRLModel</span>
        <span class="n">model_dict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;bert-base-uncased&#39;</span><span class="p">:</span> <span class="n">TFBertModel</span><span class="p">,</span>
            <span class="s1">&#39;openai-gpt&#39;</span><span class="p">:</span> <span class="n">TFOpenAIGPTModel</span><span class="p">,</span>
            <span class="s1">&#39;gpt2&#39;</span><span class="p">:</span> <span class="n">TFGPT2Model</span><span class="p">,</span>
            <span class="s1">&#39;xlnet-base-cased&#39;</span><span class="p">:</span> <span class="n">TFXLNetModel</span><span class="p">,</span>
            <span class="s1">&#39;xlm-mlm-enfr-1024&#39;</span><span class="p">:</span> <span class="n">TFXLMModel</span><span class="p">,</span>
            <span class="s1">&#39;distilbert-base-cased&#39;</span><span class="p">:</span> <span class="n">TFDistilBertModel</span><span class="p">,</span>
            <span class="s1">&#39;roberta-base&#39;</span><span class="p">:</span> <span class="n">TFRobertaModel</span><span class="p">,</span>
            <span class="s1">&#39;xlm-roberta-base&#39;</span><span class="p">:</span> <span class="n">TFXLMRobertaModel</span><span class="p">,</span>
            <span class="s1">&#39;camembert-base&#39;</span><span class="p">:</span> <span class="n">TFCamembertModel</span><span class="p">,</span>
            <span class="s1">&#39;ctrl&#39;</span><span class="p">:</span> <span class="n">TFCTRLModel</span>
        <span class="p">}</span>
        <span class="n">_model</span> <span class="o">=</span> <span class="n">model_dict</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="p">]</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">pretrained_model_name_or_path</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tmp_model_path</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;xlnet-base-cased&#39;</span><span class="p">,</span> <span class="s1">&#39;openai-gpt&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt2&#39;</span><span class="p">,</span> <span class="s1">&#39;xlm-mlm-enfr-1024&#39;</span><span class="p">):</span>
            <span class="n">_model</span><span class="o">.</span><span class="n">resize_token_embeddings</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">_model</span></div>

<div class="viewcode-block" id="TransformerTFEncoder.get_session"><a class="viewcode-back" href="../../../../../api/jina.executors.encoders.nlp.transformer.html#jina.executors.encoders.nlp.transformer.TransformerTFEncoder.get_session">[docs]</a>    <span class="k">def</span> <span class="nf">get_session</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span></div>

<div class="viewcode-block" id="TransformerTFEncoder.get_tensor_func"><a class="viewcode-back" href="../../../../../api/jina.executors.encoders.nlp.transformer.html#jina.executors.encoders.nlp.transformer.TransformerTFEncoder.get_tensor_func">[docs]</a>    <span class="k">def</span> <span class="nf">get_tensor_func</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">to_device</span><span class="p">()</span>
        <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span></div></div>


<div class="viewcode-block" id="TransformerTorchEncoder"><a class="viewcode-back" href="../../../../../api/jina.executors.encoders.nlp.transformer.html#jina.executors.encoders.nlp.transformer.TransformerTorchEncoder">[docs]</a><span class="k">class</span> <span class="nc">TransformerTorchEncoder</span><span class="p">(</span><span class="n">BaseTransformerEncoder</span><span class="p">,</span> <span class="n">BaseTextTorchEncoder</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Internally, TransformerTorchEncoder wraps the pytorch-version of transformers from huggingface.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="TransformerTorchEncoder.get_model"><a class="viewcode-back" href="../../../../../api/jina.executors.encoders.nlp.transformer.html#jina.executors.encoders.nlp.transformer.TransformerTorchEncoder.get_model">[docs]</a>    <span class="k">def</span> <span class="nf">get_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">BertModel</span><span class="p">,</span> <span class="n">OpenAIGPTModel</span><span class="p">,</span> <span class="n">GPT2Model</span><span class="p">,</span> <span class="n">XLNetModel</span><span class="p">,</span> <span class="n">XLMModel</span><span class="p">,</span> <span class="n">DistilBertModel</span><span class="p">,</span> \
            <span class="n">RobertaModel</span><span class="p">,</span> <span class="n">XLMRobertaModel</span><span class="p">,</span> <span class="n">FlaubertModel</span><span class="p">,</span> <span class="n">CamembertModel</span><span class="p">,</span> <span class="n">CTRLModel</span>
        <span class="n">model_dict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;bert-base-uncased&#39;</span><span class="p">:</span> <span class="n">BertModel</span><span class="p">,</span>
            <span class="s1">&#39;openai-gpt&#39;</span><span class="p">:</span> <span class="n">OpenAIGPTModel</span><span class="p">,</span>
            <span class="s1">&#39;gpt2&#39;</span><span class="p">:</span> <span class="n">GPT2Model</span><span class="p">,</span>
            <span class="s1">&#39;xlnet-base-cased&#39;</span><span class="p">:</span> <span class="n">XLNetModel</span><span class="p">,</span>
            <span class="s1">&#39;xlm-mlm-enfr-1024&#39;</span><span class="p">:</span> <span class="n">XLMModel</span><span class="p">,</span>
            <span class="s1">&#39;distilbert-base-cased&#39;</span><span class="p">:</span> <span class="n">DistilBertModel</span><span class="p">,</span>
            <span class="s1">&#39;roberta-base&#39;</span><span class="p">:</span> <span class="n">RobertaModel</span><span class="p">,</span>
            <span class="s1">&#39;xlm-roberta-base&#39;</span><span class="p">:</span> <span class="n">XLMRobertaModel</span><span class="p">,</span>
            <span class="s1">&#39;flaubert-base-cased&#39;</span><span class="p">:</span> <span class="n">FlaubertModel</span><span class="p">,</span>
            <span class="s1">&#39;camembert-base&#39;</span><span class="p">:</span> <span class="n">CamembertModel</span><span class="p">,</span>
            <span class="s1">&#39;ctrl&#39;</span><span class="p">:</span> <span class="n">CTRLModel</span>
        <span class="p">}</span>
        <span class="n">_model</span> <span class="o">=</span> <span class="n">model_dict</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="p">]</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tmp_model_path</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;xlnet-base-cased&#39;</span><span class="p">,</span> <span class="s1">&#39;openai-gpt&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt2&#39;</span><span class="p">,</span> <span class="s1">&#39;xlm-mlm-enfr-1024&#39;</span><span class="p">):</span>
            <span class="n">_model</span><span class="o">.</span><span class="n">resize_token_embeddings</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">_model</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">_model</span></div>

<div class="viewcode-block" id="TransformerTorchEncoder.get_session"><a class="viewcode-back" href="../../../../../api/jina.executors.encoders.nlp.transformer.html#jina.executors.encoders.nlp.transformer.TransformerTorchEncoder.get_session">[docs]</a>    <span class="k">def</span> <span class="nf">get_session</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="kn">import</span> <span class="nn">torch</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span></div>

<div class="viewcode-block" id="TransformerTorchEncoder.get_tensor_func"><a class="viewcode-back" href="../../../../../api/jina.executors.encoders.nlp.transformer.html#jina.executors.encoders.nlp.transformer.TransformerTorchEncoder.get_tensor_func">[docs]</a>    <span class="k">def</span> <span class="nf">get_tensor_func</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="kn">import</span> <span class="nn">torch</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span></div>

<div class="viewcode-block" id="TransformerTorchEncoder.array2tensor"><a class="viewcode-back" href="../../../../../api/jina.executors.encoders.nlp.transformer.html#jina.executors.encoders.nlp.transformer.TransformerTorchEncoder.array2tensor">[docs]</a>    <span class="k">def</span> <span class="nf">array2tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">array</span><span class="p">):</span>
        <span class="n">tensor</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">array2tensor</span><span class="p">(</span><span class="n">array</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensor</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">on_gpu</span> <span class="k">else</span> <span class="n">tensor</span></div>

<div class="viewcode-block" id="TransformerTorchEncoder.tensor2array"><a class="viewcode-back" href="../../../../../api/jina.executors.encoders.nlp.transformer.html#jina.executors.encoders.nlp.transformer.TransformerTorchEncoder.tensor2array">[docs]</a>    <span class="k">def</span> <span class="nf">tensor2array</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">tensor</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">on_gpu</span> <span class="k">else</span> <span class="n">tensor</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span></div></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright Jina AI Limited. All rights reserved.

    </p>
  </div> 

</footer>
        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });

      function showhide_navbar() {
      var x = document.getElementsByClassName("wy-nav-side")[0];
      var y = document.getElementsByClassName("wy-nav-content-wrap")[0];
      var z = document.getElementById("showhide-navbar-btn");
      if (x.style.display === "none") {
        x.style.display = "block";
        y.style.marginLeft = "23rem";
        z.style.left = "23rem";
      } else {
        x.style.display = "none";
        y.style.marginLeft = "0";
        z.style.left = "0px";
      }
    }
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-164627626-3', 'auto');
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>