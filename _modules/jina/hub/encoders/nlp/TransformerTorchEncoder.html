

<!DOCTYPE html>
<html lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="X-UA-Compatible" content="IE=edge">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@JinaAI_">
<meta name="twitter:creator" content="@JinaAI_">
<meta name="description"
      content="Jina is the cloud-native neural search solution powered by the state-of-the-art AI and deep learning">
<meta property="og:title" content="Jina Documentation">
<meta property="og:description"
      content="Jina is the cloud-native neural search solution powered by the state-of-the-art AI and deep learning">
<meta property="og:url" content="https://opensource.jina.ai">
<meta property="og:image" content="../../../../../_static/banner.png">
<meta property="og:type" content="website">
<link rel="icon" href="../../../../../_static/favicon.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
  <title>jina.hub.encoders.nlp.TransformerTorchEncoder &mdash; Jina 0.6.1 documentation</title>
  

  
  <link rel="stylesheet" href="../../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../_static/main.css" type="text/css" />

<!--  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/1.0.0/css/materialize.min.css">-->


  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../../" src="../../../../../_static/documentation_options.js"></script>
        <script src="../../../../../_static/jquery.js"></script>
        <script src="../../../../../_static/underscore.js"></script>
        <script src="../../../../../_static/doctools.js"></script>
        <script src="../../../../../_static/language_data.js"></script>
        <script src="../../../../../_static/clipboard.min.js"></script>
        <script src="../../../../../_static/copybutton.js"></script>
    
    <script type="text/javascript" src="../../../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../../index.html">
          

          
            
            <img src="../../../../../_static/jina-prod-logo.svg" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.6.1
              </div>
            
          


          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Install</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/install/via-pip.html">Install Jina via <code class="docutils literal notranslate"><span class="pre">pip</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/install/via-docker.html">Install Jina via Docker Container</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/install/on-rasp-linux.html">Install Jina on Raspberry Pi and other Linux Systems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/install/on-x.html">Can I Run Jina On ‚Ä¶.?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/install/upgrade.html">Upgrade Jina</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/install/autocomplete.html">Autocomplete commands on Bash, Zsh and Fish</a></li>
</ul>
<p class="caption"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/helloworld/index.html">Jina ‚ÄúHello, World!‚Äù üëãüåç</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/101/.sphinx.html">Jina 101: First Thing to Learn About Jina</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/flow/index.html">Using Flow API to Compose Your Jina Workflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/flow/index.html#common-design-patterns">Common Design Patterns</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/io/index.html">Input and Output Functions in Jina</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/hub/index.html">Using Jina Pod with Docker Container</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/remote/index.html">Using Jina Pod Remotely</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/dashboard/index.html">Using Dashboard to Monitor Logs and View Flow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/cli/exit.html">Gracefully Exit Jina</a></li>
</ul>
<p class="caption"><span class="caption-text">Developer Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/cli/index.html">Jina Command-Line Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../api/jina.html">Jina Python API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/yaml/yaml.html">Jina YAML Syntax Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/simple_exec.html">Built-in Simple Executors and Reserved <code class="docutils literal notranslate"><span class="pre">uses</span></code> in Jina</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/proto/index.html">Jina Protobuf Specification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/restapi/index.html">Jina REST API Specification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/envs.html">OS Environment Variables Used in Jina</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/api_schema.html">Jina API Schema for 3rd-Party Applications</a></li>
</ul>
<p class="caption"><span class="caption-text">Extending Jina</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/extend/mwu.html">A Minimum Working Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/extend/executor.html">Guideline When Adding New Executor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/extend/driver.html">Guideline When Adding New Driver</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/hub/publish-your-pod-image.html">Publish Your Pod Image to Jina Hub</a></li>
</ul>
<p class="caption"><span class="caption-text">Contributing</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/CONTRIBUTING.html">Contributing to Jina</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/jep/index.html">Jina Enhancement Proposals (JEP)</a></li>
</ul>
<p class="caption"><span class="caption-text">Release Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/RELEASE.html">Release Cycle</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/CHANGELOG.html">Change Logs</a></li>
</ul>
<p class="caption"><span class="caption-text">Debugging and FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/troubleshooting.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/faq/user.html">FAQ for End-Users</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/faq/dev.html">FAQ for Developers</a></li>
</ul>
<p class="caption"><span class="caption-text">Indices and Tables</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/all_exec.html">List of 80 Executors in Jina</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../chapters/all_driver.html">List of 35 Drivers in Jina</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../index.html">Jina</a>
        
      </nav>

   
      <div class="wy-nav-content">
        
        <div class="rst-content style-external-links">
        
          















<div role="navigation" aria-label="breadcrumbs navigation" class="nav-bar-header">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../../../../index.html">Module code</a> &raquo;</li>
        
          <li><a href="../../../../jina.html">jina</a> &raquo;</li>
        
      <li>jina.hub.encoders.nlp.TransformerTorchEncoder</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  
<div role="search" class="nav-bar-search">
  <form id="rtd-search-form" class="wy-form doc-searchbox" action="../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs (Press / to focus)" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

</div>
<hr/>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for jina.hub.encoders.nlp.TransformerTorchEncoder</h1><div class="highlight"><pre>
<span></span><span class="n">__copyright__</span> <span class="o">=</span> <span class="s2">&quot;Copyright (c) 2020 Jina AI Limited. All rights reserved.&quot;</span>
<span class="n">__license__</span> <span class="o">=</span> <span class="s2">&quot;Apache-2.0&quot;</span>

<span class="kn">from</span> <span class="nn">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">jina.executors.decorators</span> <span class="kn">import</span> <span class="n">batching</span><span class="p">,</span> <span class="n">as_ndarray</span>
<span class="kn">from</span> <span class="nn">jina.executors.devices</span> <span class="kn">import</span> <span class="n">TorchDevice</span>
<span class="kn">from</span> <span class="nn">jina.executors.encoders</span> <span class="kn">import</span> <span class="n">BaseEncoder</span>
<span class="kn">from</span> <span class="nn">jina.executors.encoders.helper</span> <span class="kn">import</span> <span class="n">reduce_mean</span><span class="p">,</span> <span class="n">reduce_max</span><span class="p">,</span> <span class="n">reduce_min</span><span class="p">,</span> <span class="n">reduce_cls</span>
<span class="kn">from</span> <span class="nn">jina.helper</span> <span class="kn">import</span> <span class="n">cached_property</span>
<span class="kn">from</span> <span class="nn">jina.logging</span> <span class="kn">import</span> <span class="n">default_logger</span>


<div class="viewcode-block" id="auto_reduce"><a class="viewcode-back" href="../../../../../api/jina.hub.encoders.nlp.TransformerTorchEncoder.html#jina.hub.encoders.nlp.TransformerTorchEncoder.auto_reduce">[docs]</a><span class="k">def</span> <span class="nf">auto_reduce</span><span class="p">(</span><span class="n">model_outputs</span><span class="p">:</span> <span class="s1">&#39;np.ndarray&#39;</span><span class="p">,</span> <span class="n">mask_2d</span><span class="p">:</span> <span class="s1">&#39;np.ndarray&#39;</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s1">&#39;np.ndarray&#39;</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Automatically creates a sentence embedding from its token embeddings.</span>
<span class="sd">        * For BERT-like models (BERT, RoBERTa, DistillBERT, Electra ...) uses embedding of first token</span>
<span class="sd">        * For XLM and XLNet models uses embedding of last token</span>
<span class="sd">        * Assumes that other models are language-model like and uses embedding of last token</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="s1">&#39;bert&#39;</span> <span class="ow">in</span> <span class="n">model_name</span> <span class="ow">or</span> <span class="s1">&#39;electra&#39;</span> <span class="ow">in</span> <span class="n">model_name</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">reduce_cls</span><span class="p">(</span><span class="n">model_outputs</span><span class="p">,</span> <span class="n">mask_2d</span><span class="p">)</span>
    <span class="k">if</span> <span class="s1">&#39;xlnet&#39;</span> <span class="ow">in</span> <span class="n">model_name</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">reduce_cls</span><span class="p">(</span><span class="n">model_outputs</span><span class="p">,</span> <span class="n">mask_2d</span><span class="p">,</span> <span class="n">cls_pos</span><span class="o">=</span><span class="s1">&#39;tail&#39;</span><span class="p">)</span>
    <span class="n">default_logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;Using embedding of a last token as a sequence embedding. &#39;</span>
                           <span class="s1">&#39;If that is not desirable, change `pooling_strategy`&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">reduce_cls</span><span class="p">(</span><span class="n">model_outputs</span><span class="p">,</span> <span class="n">mask_2d</span><span class="p">,</span> <span class="n">cls_pos</span><span class="o">=</span><span class="s1">&#39;tail&#39;</span><span class="p">)</span></div>


<div class="viewcode-block" id="Transformer"><a class="viewcode-back" href="../../../../../api/jina.hub.encoders.nlp.TransformerTorchEncoder.html#jina.hub.encoders.nlp.TransformerTorchEncoder.Transformer">[docs]</a><span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">Transformer</span><span class="p">:</span>
    <span class="n">pretrained_model_name_or_path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;bert-base-uncased&#39;</span>
    <span class="n">pooling_strategy</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;auto&#39;</span>
    <span class="n">max_length</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">truncation_strategy</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;longest_first&#39;</span>
    <span class="n">model_save_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span></div>


<div class="viewcode-block" id="TransformerTorchEncoder"><a class="viewcode-back" href="../../../../../api/jina.hub.encoders.nlp.TransformerTorchEncoder.html#jina.hub.encoders.nlp.TransformerTorchEncoder.TransformerTorchEncoder">[docs]</a><span class="k">class</span> <span class="nc">TransformerTorchEncoder</span><span class="p">(</span><span class="n">TorchDevice</span><span class="p">,</span> <span class="n">BaseEncoder</span><span class="p">,</span> <span class="n">Transformer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Internally, TransformerTorchEncoder wraps the tensorflow-version of transformers from huggingface.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param pretrained_model_name_or_path: Either:</span>
<span class="sd">            - a string with the `shortcut name` of a pre-trained model to load from cache or download, e.g.: ``bert-base-uncased``.</span>
<span class="sd">            - a string with the `identifier name` of a pre-trained model that was user-uploaded to Hugging Face S3, e.g.: ``dbmdz/bert-base-german-cased``.</span>
<span class="sd">            - a path to a `directory` containing model weights saved using :func:`~transformers.PreTrainedModel.save_pretrained`, e.g.: ``./my_model_directory/``.</span>
<span class="sd">            - a path or url to a `tensorflow index checkpoint file` (e.g. `./tf_model/model.ckpt.index`). In this case, ``from_tf`` should be set to True and a configuration object should be provided as ``config`` argument.</span>
<span class="sd">            This loading path is slower than converting the TensorFlow</span>
<span class="sd">            checkpoint in a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</span>
<span class="sd">        :param pooling_strategy: the strategy to merge the word embeddings into the chunk embedding. Supported</span>
<span class="sd">            strategies include &#39;auto&#39;, &#39;cls&#39;, &#39;mean&#39;, &#39;max&#39;, &#39;min&#39;.</span>
<span class="sd">        :param max_length: the max length to truncate the tokenized sequences to.</span>
<span class="sd">        :param model_save_path: the path of the encoder model. If a valid path is given, the encoder will be saved to the given path</span>
<span class="sd">        :param truncation_strategy: select truncation strategy. Supported values</span>
<span class="sd">            * `True` or `&#39;longest_first&#39;` (default): truncate to a max length specified in `max_length` or to the max acceptable input length for the model if no length is provided (`max_length=None`).</span>
<span class="sd">            * `&#39;only_first&#39;`:  This will only truncate the first sequence of a pair if a pair of sequences (or a batch of pairs) is provided</span>
<span class="sd">            * `&#39;only_second&#39;`: This will only truncate the second sequence of a pair if a pair of sequences (or a batch of pairs) is provided</span>
<span class="sd">            * `False` or `&#39;do_not_truncate&#39;`: No truncation (i.e. can output batch with sequences length greater than the model max admissible input size)</span>

<span class="sd">        ..warning::</span>
<span class="sd">            `model_save_path` should be relative to executor&#39;s workspace</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_save_path</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_abspath</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;create folder for saving transformer models: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_abspath</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
                <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_abspath</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_abspath</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_abspath</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__getstate__</span><span class="p">()</span>

<div class="viewcode-block" id="TransformerTorchEncoder.array2tensor"><a class="viewcode-back" href="../../../../../api/jina.hub.encoders.nlp.TransformerTorchEncoder.html#jina.hub.encoders.nlp.TransformerTorchEncoder.TransformerTorchEncoder.array2tensor">[docs]</a>    <span class="k">def</span> <span class="nf">array2tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">array</span><span class="p">):</span>
        <span class="kn">import</span> <span class="nn">torch</span>
        <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">array</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensor</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">on_gpu</span> <span class="k">else</span> <span class="n">tensor</span></div>

<div class="viewcode-block" id="TransformerTorchEncoder.tensor2array"><a class="viewcode-back" href="../../../../../api/jina.hub.encoders.nlp.TransformerTorchEncoder.html#jina.hub.encoders.nlp.TransformerTorchEncoder.TransformerTorchEncoder.tensor2array">[docs]</a>    <span class="k">def</span> <span class="nf">tensor2array</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">tensor</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">on_gpu</span> <span class="k">else</span> <span class="n">tensor</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">model_abspath</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Get the file path of the encoder model storage</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_file_from_workspace</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_save_path</span><span class="p">)</span>

    <span class="nd">@cached_property</span>
    <span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForPreTraining</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForPreTraining</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pretrained_model_name_or_path</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">model</span>

    <span class="nd">@cached_property</span>
    <span class="k">def</span> <span class="nf">no_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="kn">import</span> <span class="nn">torch</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span>

    <span class="nd">@cached_property</span>
    <span class="k">def</span> <span class="nf">tensor_func</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="kn">import</span> <span class="nn">torch</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span>

    <span class="nd">@cached_property</span>
    <span class="k">def</span> <span class="nf">tokenizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>
        <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pretrained_model_name_or_path</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tokenizer</span>

<div class="viewcode-block" id="TransformerTorchEncoder.encode"><a class="viewcode-back" href="../../../../../api/jina.hub.encoders.nlp.TransformerTorchEncoder.html#jina.hub.encoders.nlp.TransformerTorchEncoder.TransformerTorchEncoder.encode">[docs]</a>    <span class="nd">@batching</span>
    <span class="nd">@as_ndarray</span>
    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="s1">&#39;np.ndarray&#39;</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s1">&#39;np.ndarray&#39;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param data: a 1d array of string type in size `B`</span>
<span class="sd">        :return: an ndarray in size `B x D`</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">add_special_tokens</span><span class="p">({</span><span class="s1">&#39;pad_token&#39;</span><span class="p">:</span> <span class="s1">&#39;[PAD]&#39;</span><span class="p">})</span>
            <span class="n">ids_info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_encode_plus</span><span class="p">(</span><span class="n">data</span><span class="p">,</span>
                                                        <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_length</span><span class="p">,</span>
                                                        <span class="n">truncation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">truncation_strategy</span><span class="p">,</span>
                                                        <span class="n">pad_to_max_length</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">resize_token_embeddings</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">))</span>
            <span class="n">ids_info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_encode_plus</span><span class="p">(</span><span class="n">data</span><span class="p">,</span>
                                                        <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_length</span><span class="p">,</span>
                                                        <span class="n">pad_to_max_length</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">token_ids_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">array2tensor</span><span class="p">(</span><span class="n">ids_info</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">])</span>
        <span class="n">mask_ids_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">array2tensor</span><span class="p">(</span><span class="n">ids_info</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">no_gradients</span><span class="p">():</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">token_ids_batch</span><span class="p">,</span>
                                 <span class="n">attention_mask</span><span class="o">=</span><span class="n">mask_ids_batch</span><span class="p">,</span>
                                 <span class="n">output_hidden_states</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">output_embeddings</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">_mask_ids_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor2array</span><span class="p">(</span><span class="n">mask_ids_batch</span><span class="p">)</span>
            <span class="n">_seq_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor2array</span><span class="p">(</span><span class="n">output_embeddings</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pooling_strategy</span> <span class="o">==</span> <span class="s1">&#39;auto&#39;</span><span class="p">:</span>
                <span class="n">output</span> <span class="o">=</span> <span class="n">auto_reduce</span><span class="p">(</span><span class="n">_seq_output</span><span class="p">,</span> <span class="n">_mask_ids_batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">base_model_prefix</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">pooling_strategy</span> <span class="o">==</span> <span class="s1">&#39;mean&#39;</span><span class="p">:</span>
                <span class="n">output</span> <span class="o">=</span> <span class="n">reduce_mean</span><span class="p">(</span><span class="n">_seq_output</span><span class="p">,</span> <span class="n">_mask_ids_batch</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">pooling_strategy</span> <span class="o">==</span> <span class="s1">&#39;max&#39;</span><span class="p">:</span>
                <span class="n">output</span> <span class="o">=</span> <span class="n">reduce_max</span><span class="p">(</span><span class="n">_seq_output</span><span class="p">,</span> <span class="n">_mask_ids_batch</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">pooling_strategy</span> <span class="o">==</span> <span class="s1">&#39;min&#39;</span><span class="p">:</span>
                <span class="n">output</span> <span class="o">=</span> <span class="n">reduce_min</span><span class="p">(</span><span class="n">_seq_output</span><span class="p">,</span> <span class="n">_mask_ids_batch</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;pooling strategy not found: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">pooling_strategy</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span>
        <span class="k">return</span> <span class="n">output</span></div></div>

</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright Jina AI Limited. All rights reserved.

    </p>
  </div> 

</footer>
        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });

      function showhide_navbar() {
      var x = document.getElementsByClassName("wy-nav-side")[0];
      var y = document.getElementsByClassName("wy-nav-content-wrap")[0];
      var z = document.getElementById("showhide-navbar-btn");
      if (x.style.display === "none") {
        x.style.display = "block";
        y.style.marginLeft = "23rem";
        z.style.left = "23rem";
      } else {
        x.style.display = "none";
        y.style.marginLeft = "0";
        z.style.left = "0px";
      }

    }
    function showhide_littlenavbar() {
      var x = document.getElementById("little-navbar");
      if (x.style.display === "none") {
        x.style.display = "block";
      } else {
        x.style.display = "none";
      }
    }
  </script>

  <!-- Search box becomes active when you press the slash(/) key anywhere on the page-->
  <script>
    const body = document.querySelector('body');
    const searchBox = document.querySelector('form').querySelector('input[type="text"]');

    body.addEventListener('keyup', event => {
      event.preventDefault()
      if (event.key === '/') {
        searchBox.focus();
      }
    });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-164627626-3', 'auto');
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>